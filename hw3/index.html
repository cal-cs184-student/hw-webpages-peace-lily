<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 3 Write-Up</h1>
		<div style="text-align: center;">Names: Abby Brooks-Ramirez, Richard Villagomez</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-peace-lily/hw3/index.html">hw-webpages-peace-lily/hw3/index.html</a><br>
		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw3-pothos">cal-cs184-student/teams/pothos</a>
		<!--
		<figure>
			<img src="cornell.png" alt="Cornell Boxes with Bunnies" style="width:70%"/>
			<figcaption>You can add images with captions!</figcaption>
		</figure>
-->
		<!--
		We've already added one heading per part, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		Give a high-level overview of what you implemented in this homework. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the homework.
		
		<h2>Part 1: Ray Generation and Scene Intersection</h2>
		<p>
			For Part 1, I focused on generating rays from the camera and implementing intersection logic for triangles and spheres. In <code>Camera::generate_ray</code>, I mapped normalized screen coordinates \((x, y)\) to the canonical sensor plane at \(z = -1\) in camera space. Using the horizontal and vertical fields of view, I computed the sensor width and height, centered the plane at the origin, and scaled the input coordinates accordingly. Since the camera looks down the -Z axis, I created rays pointing from the origin through the sensor point, then transformed them into world space using the <code>c2w</code> matrix. Finally, I normalized the direction and initialized the ray with the camera’s near and far clip planes.
			</p>
			
			<p>
			In <code>PathTracer::raytrace_pixel</code>, I generated one or more rays per pixel and averaged the estimated radiance:
			</p>
			
			<ul>
			  <li>If <code>ns_aa == 1</code>, I generated a single ray through the pixel center.</li>
			  <li>If anti-aliasing was enabled, I used <code>gridSampler</code> to generate stratified subpixel offsets and traced <code>ns_aa</code> rays per pixel.</li>
			</ul>
			
			<p>
			I then implemented triangle intersection using the Möller–Trumbore algorithm from Lecture 9 in <code>Triangle::intersect</code>. After computing edge vectors and checking the determinant to avoid degenerate triangles, I solved for barycentric coordinates \((u, v)\) to confirm the intersection is inside the triangle. For valid hits, I used the barycentric weights to interpolate the normal from the triangle’s vertex normals and populated the <code>Intersection</code> struct.
			</p>
			
			<p>
			For spheres, I solved the quadratic ray-sphere intersection equation in <code>Sphere::test</code> and used it in both <code>has_intersection</code> and <code>intersect</code>. I selected the nearest valid root and computed the normal as the normalized vector from the sphere center to the hit point.
			</p>
			
			<p>
			The following debug renderings helped verify everything was working:
			</p>
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
					<tr>
						<td colspan="2">
						  <figure>
							<img src="images/banana.png" width="400px"/>
							<figcaption>banana.dae</figcaption>
						  </figure>
						</td>
					  </tr>
				  <tr>
					<td>
					  <img src="images/CBspheres.png" width="400px"/>
					  <figcaption>CBspheres.dae</figcaption>
					</td>
					<td>
					  <img src="images/CBdragon.png" width="400px"/>
					  <figcaption>CBdragon.dae</figcaption>
					</td>
				  </tr>
				</table>
			  </div>
			
<!--
		<p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="cornell.png" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
	-->
		<h2>Part 2: Bounding Volume Hierarchy</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 3: Direct Illumination</h2>
<p>
  This part was all about implementing direct lighting using two different sampling strategies: uniform hemisphere sampling and importance sampling. Both approaches try to estimate the light coming from area lights directly, but with different levels of noise and efficiency.
</p>

<p>
  I first implemented <code>estimate_direct_lighting_hemisphere</code>, where I uniformly sampled directions over the hemisphere above the surface. For each sampled direction, I traced a shadow ray from the hit point and checked if it intersected any light-emitting objects. If it did, I applied the reflection equation using the BSDF’s <code>f()</code> function and the cosine between the sampled direction and the surface normal. This worked, but it's very noisy—even with a decently high number of samples—since most directions don't actually point toward light sources.
</p>

<p>
  Then I implemented <code>estimate_direct_lighting_importance</code>. Instead of sampling random directions in the hemisphere, this one directly samples the lights in the scene. For each light, I generated rays toward sampled points on the light and checked if they were occluded. If not, I used the reflectance equation again, normalized by the PDF of the light sample. Point lights were only sampled once since they don’t have area. This method produces way cleaner results with fewer samples.
</p>

<p>
  To test both, I rendered the same scene with hemisphere sampling and then with importance sampling at 1, 4, 16, and 64 light samples. For all of them, I kept the number of camera rays per pixel at 1 to highlight the difference in noise levels.
</p>

<div style="display: flex; flex-direction: column; align-items: center;">
  <table style="width: 100%; text-align: center; border-collapse: collapse;">
    <tr>
      <td>
        <img src="images/CBbunny_H_16_8.png" width="400px"/>
        <figcaption>hemisphere sampling -- 16 light samples, 8 bounces</figcaption>
      </td>
      <td>
        <img src="images/CBbunny_L_1.png" width="400px"/>
        <figcaption>importance sampling -- 1 light sample, 1 pixel sample</figcaption>
      </td>
    </tr>
    <tr>
      <td>
        <img src="images/CBbunny_L_4.png" width="400px"/>
        <figcaption>importance sampling -- 4 light samples, 1 pixel sample</figcaption>
      </td>
      <td>
        <img src="images/CBbunny_L_16.png" width="400px"/>
        <figcaption>importance sampling -- 16 light samples, 1 pixel sample</figcaption>
      </td>
    </tr>
    <tr>
		<td colspan="2" style="text-align: center;">
			<img src="images/CBbunny_L_64.png" width="400px"/>
        <figcaption>importance sampling -- 64 light samples, 1 pixel sample</figcaption>
      </td>
    </tr>
  </table>
</div>

<p>
  Overall, importance sampling was a big improvement. Even at 4 samples, the shadows were a lot cleaner than the hemisphere version with 16. At 64, it’s basically clean with soft shadows and much less noise. The hemisphere sampling "wastes" a lot of samples shooting rays into directions that never hit lights. Importance sampling is more focused and efficient, and makes a noticeable difference overall.
</p>


		<h2>Part 4: Global Illumination</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>Part 5: Adaptive Sampling</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

		<h2>(Optional) Part 6: Extra Credit Opportunities</h2>
		Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
		
		<h2>Additional Notes (please remove)</h2>
		<ul>
			<li>You can also add code if you'd like as so: <code>code code code</code></li>
			<li>If you'd like to add math equations, 
				<ul>
					<li>You can write inline equations like so: \( a^2 + b^2 = c^2 \)</li>
					<li>You can write display equations like so: \[ a^2 + b^2 = c^2 \]</li>
				</ul>
			</li>
		</ul>
		</div>
	</body>
</html>